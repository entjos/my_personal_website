{
  "hash": "d6e86766ac3f314921dd03d12d13cdde",
  "result": {
    "markdown": "---\ntitle: \"Optimisation of a Weibull survival model using Optimx() in R\"\nauthor: \"Joshua Philipp Entrop\"\ndate: '2020-09-28'\ncategories: [Optimisation, R]\ntags: [R, survival analysis, manual optimisation]\ndraft: FALSE\n---\n\n\nIn this blog post we will optimise a Weibull regression model by maximising its likelihood function using <TT>optimx()</TT> from the <TT>{optimx}</TT> package in R. In my previous blog post I showed how to optimise a Poisson regression model in the same manner. Optimising a Poisson and Weibull survival model using the likelihood function is quite similar. Hence, if you have any difficulties following this blog post, I would recommend you to read my previous blog post on optimising a Poisson regression model first. You can find my previous blog post [here](https://www.joshua-entrop.com/post/optim_pois_reg/). Please note, that you can download the <TT>R</TT> code that we will use throughout this post [here](https://www.joshua-entrop.com/rcode/optim_weibull_reg.txt).\n\nAs in my previous blog posts, we will use the lung cancer data set included in the <TT>{survival}</TT> package as example for this post. For more information on this data set please take a look at the help file <TT>?survival::lung</TT> Specifically, we will model the survival of lung cancer patients in this data set by sex and age. This time we will use a Weibull regression model instead of a Poisson regression model to analyse the association between age, sex and survival of lung cancer patients.\n\nThe general survival function of a Weibull regression model can be specified as\n\n$$ S(t) = \\exp(\\lambda t ^ \\gamma). $$\n\nBy introducing the exponent $\\gamma$ in the term below, we allow the hazard to change over time. Hence, we do not need to assume a constant hazard function across time of follow up. Just as a reminder in the Possion regression model our hazard function was just equal to $\\lambda$. In case of a Weibull regression model our hazard function is\n\n$$ h(t) = \\gamma \\lambda t ^ {\\gamma -1} $$\n\nwhere\n\n$$ \\lambda = \\exp(\\alpha + \\beta_1  x_{female} + \\beta_2  x_{age}). $$\n\nUsing this more complex hazard function we can fit changes in the hazard across time of follow up.\n\nSo now let's get started with loading the data set and setting up the variables.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# 1. Prefix -------------------------------------------------------------------\n\n# Remove all files from ls\nrm(list = ls())\n\n# Loading packages\nrequire(survival)\nrequire(flexsurv)\nrequire(optimx)\nrequire(numDeriv)\nrequire(dplyr)\nrequire(tibble)\nrequire(car)\n\n# 2. Loading dataset ----------------------------------------------------------\n\n#Reading the example data set lung from the survival package\nlung <- as.data.frame(survival::lung)\n\n#Recode dichotomous vairables\nlung$female <- ifelse(lung$sex == 2, 1, 0)\nlung$status_n <- ifelse(lung$status == 2, 1, 0)\n```\n:::\n\n\nIf we now want to use the likelihood function to fit our Weibull regression model we first need to specify our likelihood function. The general likelihood function for survival model can be written as\n\n$$ \\ln L_i = d_i \\ln h(t_i) + \\ln S(t_i). $$\n\nBy substituting our previous defined hazard and survival function we get\n\n$$ \\ln L = d \\ln(\\gamma \\lambda t ^ {\\gamma - 1}) + \\exp(\\lambda) t ^ \\gamma $$\n\nfor the log likelihood function of our Weibull model. To find the estimates of our Weibull model that best fit our data, we need to find the maximum of this function. Hence, the next step is to implement this function in <TT>R</TT> so that we can use it for our <TT>optimx()</TT> call.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# 3. Define log-likelihood function for Weibull regression model --------------\nnegll <- function(par){\n  \n  #Extract guesses for alpha, gamma, beta1 and beta2\n  gamma <- par[1]\n  alpha <- par[2]\n  beta1 <- par[3]\n  beta2 <- par[4]\n  \n  #Define dependent and independent variables\n  t  <- lung$time\n  d  <- lung$status_n\n  x1 <- lung$female\n  x2 <- lung$age\n  \n  #Calculate lambda and gamma\n  lambda <- (alpha + beta1 * x1 + beta2 * x2)\n  egamma <- exp(gamma)\n  \n  #Estimate negetive log likelihood value\n  val <- -sum(d * (log(egamma * t ^ (egamma - 1)) + lambda) - \n                exp(lambda) * t ^ egamma)\n  \n  return(val)\n}\n```\n:::\n\n\nAdditionally, we can pass the analytical gradient function of our likelihood function to our <TT>optimx()</TT> call to improve our estimates. After partially deriving our log likelihood function $\\ln L_i$ for $\\alpha$, $\\gamma$ and $\\beta_i$, we yield the following equations for the gradient of $\\ln L_i$.\n\n$$ \n\\sum d_i - \\exp(\\lambda_i) t_i ^ {\\exp(\\gamma_i)} = 0 \n$$\n\n$$\n\\sum (d_i \\ln(t_i) - t_i \\exp(\\gamma_i) \\ln(t_i) \\exp(\\lambda_i)) \\exp(\\gamma_i) + d_i = 0 \n$$ $$\n\\sum d_i * x_{ij} - \\exp(\\lambda_i) x_{ij} t_i ^ {\\exp(\\gamma_i)} = 0\n$$\n\nUsing these equations we get the following function for our gradient in <TT>R</TT>.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# 4. Define gradient function for Weibull regression model --------------------\nnegll.grad <- function(par){\n  \n  #Extract guesses for alpha, gamma, beta1 and beta2\n  gamma <- par[1]\n  alpha <- par[2]\n  beta1 <- par[3]\n  beta2 <- par[4]\n  \n  #Define dependent and independent variables\n  t  <- lung$time\n  d  <- lung$status_n\n  x1 <- lung$female\n  x2 <- lung$age\n  \n  #Create output vector\n  n <- length(par[1])\n  gg <- as.vector(rep(0, n))\n  \n  #Calculate lambda\n  lambda <- (alpha + beta1 * x1 + beta2 * x2)\n  \n  #Calculate partial gradient functions\n  gg[1] <- -sum((d * log(t) - \n                   t ^ exp(gamma) * log(t) * exp(lambda)) * exp(gamma) + d)\n  \n  gg[2] <- -sum(d - exp(lambda) * t ^ exp(gamma))\n  gg[3] <- -sum(d * x1 - exp(lambda) * x1 * t ^ exp(gamma))\n  gg[4] <- -sum(d * x2 - exp(lambda) * x2 * t ^ exp(gamma))\n  \n  return(gg)\n}\n```\n:::\n\n\nLet's do some quality check on our gradient functions. For this we compare the estimates of our gradient functions with the approximation from the <TT>numDeriv::numgrad()</TT> function.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# 4.1 Compare gradient functiona with numeric approximation of gradient =======\n# compare gradient at 1, 0, 0, 0\nmygrad <- negll.grad(c(1, 0, 0, 0))\nnumgrad <- grad(x = c(1, 0, 0, 0), func = negll)\n\nall.equal(mygrad, numgrad)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] TRUE\n```\n:::\n:::\n\n\nAll good, we get the same results. Now is the time to get all functions and data together and pass them to our <TT>optimx()</TT> call to get the maximum likelihood estimates for our Weibull model.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# 5. Find minimum of log-likelihood function ----------------------------------\n# Passing names to the values in the par vector improves readability of results\nopt <- optimx(par = c(gamma = 1, alpha = 0, beta_female = 0, beta_age = 0), \n              fn = negll,\n              gr = negll.grad,\n              hessian = TRUE,\n              control = list(trace = 0, all.methods = TRUE))\n\n# Show results for optimisation alogrithms, that convergered (convcode == 0)\nsummary(opt, order = \"value\") %>%\n  rownames_to_column(\"algorithm\") %>% \n  filter(convcode == 0) %>% \n  select(algorithm, gamma, alpha, beta_female, beta_age, value)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n    algorithm         gamma     alpha beta_female     beta_age       value\n1      newuoa   0.282294079 -8.828209  -0.5067097   0.01625468    1147.054\n2      nlminb   0.282296689 -8.828269  -0.5067118   0.01625527    1147.054\n3        BFGS   0.282291577 -8.828211  -0.5067102   0.01625510    1147.054\n4      bobyqa   0.282291455 -8.828164  -0.5067134   0.01625432    1147.054\n5    L-BFGS-B   0.282257770 -8.828116  -0.5065362   0.01625512    1147.054\n6 Nelder-Mead   0.004418373  0.702934  -0.4134191  -0.10870858    1271.990\n7         nlm -23.931210572 -1.433331  -0.6337426 -88.76207627  931946.566\n8      Rcgmin   1.000000000  0.000000   0.0000000   0.00000000 6629012.776\n```\n:::\n:::\n\n\nAccording to our table the <TT>newuoa</TT> algorithm from the <TT>{minqa}</TT> package yielded the best estimates. The <TT>newuoa</TT> algorithm was developed to find the minimum of a function without information about the analytical gradient function. Instead the algorithm uses a quadratic approximation of the gradient function to minimise the function of interest. Interestingly, the <TT>newuoa</TT> algorithm yielded a higher likelihood than the <TT>nlminb</TT> algorithm that uses the analytical gradient function.\n\nLet's now compare our results with the results from the <TT>flexsurvreg()</TT> function from the <TT>{flexsurv}</TT> package.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# 6. Estimate regression coeficents using flexsurvreg -------------------------\nweibull_model <- flexsurvreg(Surv(time, status_n == 1) ~ female + age, \n                          data = lung,\n                          dist = \"weibullph\")\n\n# 7. Comparing results from optimx and flexsurvreg ----------------------------\nweibull_results <- unname(coef(weibull_model))\ncoef_opt <- coef(opt)\n\nlapply(1:nrow(coef_opt), function(i){\n  \n  opt_name <- attributes(coef_opt)$dimnames[[1]][i]\n  \n  mle_weibl1 <- (coef_opt[i, 1] - weibull_results[1])\n  mle_weibl2 <- (coef_opt[i, 2] - weibull_results[2])\n  mle_weibl3 <- (coef_opt[i, 3] - weibull_results[3])\n  mle_weibl4 <- (coef_opt[i, 4] - weibull_results[4])\n  \n  mean_dif <- mean(mle_weibl1, mle_weibl2, mle_weibl3, mle_weibl4, \n                   na.rm = TRUE)\n  \n  data.frame(opt_name, mean_dif)\n  \n}) %>% \n  bind_rows() %>% \n  filter(!is.na(mean_dif)) %>% \n  mutate(mean_dif = abs(mean_dif)) %>% \n  arrange(mean_dif)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n      opt_name     mean_dif\n1       newuoa 1.264708e-06\n2       nlminb 1.345317e-06\n3         BFGS 3.766647e-06\n4       bobyqa 3.888642e-06\n5     L-BFGS-B 3.757310e-05\n6  Nelder-Mead 2.778770e-01\n7       Rcgmin 7.177047e-01\n8       Rvmmin 7.177047e-01\n9           CG 2.864370e+00\n10         nlm 2.421351e+01\n```\n:::\n:::\n\n\nWe can see that the differences between our estimates and the estimates we would have gotten if we used <TT>flexsurvreg()</TT> to fit our model, are close to null. At least for the estimates yielded by the <TT>newuoa</TT> algorithm.\n\nSince we found the point estimates for our Weibull regression, we can now take the next step and calculate confidence intervals (CIs) for our estimates. For this we will use the Hessian matrix of our model. If you cannot follow the code below, please take a look at my [previouse post](https://www.joshua-entrop.com/post/optim_logit_reg_se/) where I explained how to compute CIs for estimates of a logistic regression model using the same approach.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# 8. Estimate the standard error ----------------------------------------------\n\n#Extract hessian matrix for Newuoa optimisation\nhessian_m <- attributes(opt)$details[\"newuoa\", \"nhatend\"][[1]]\n\n# Estimate se based on hession matrix\nfisher_info <- solve(hessian_m)\nprop_se  <- sqrt(diag(fisher_info))\n\n# Compare the estimated se from our model with the one from the flexsurv model\n# Note use res.t to get the estimates on the reale scale without transformaiton\nses <- data.frame(se_newuoa = prop_se,\n                  se_felxsurvreg = weibull_model$res.t[, \"se\"]) %>%\n  print()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n         se_newuoa se_felxsurvreg\nshape  0.061883266    0.061869493\nscale  0.777802040    0.777206348\nfemale 0.167066129    0.167066105\nage    0.009188029    0.009170499\n```\n:::\n\n```{.r .cell-code}\nall.equal(ses[,\"se_newuoa\"], ses[, \"se_felxsurvreg\"])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Mean relative difference: 0.0006171813\"\n```\n:::\n\n```{.r .cell-code}\n# 9. Estimate 95%CIs using estimation of SE -----------------------------------\n\n# Extracting estimates from Newuoa optimisaiton\ncoef_test <- coef(opt)[\"newuoa\",]\n\n# Compute 95%CIs\nupper <- coef_test + 1.96 * prop_se\nlower <- coef_test - 1.96 * prop_se\n\n# Print 95%CIs\ndata.frame(Estimate = coef_test,\n           CI_lower = lower,\n           CI_upper = upper,\n           se       = prop_se)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n               Estimate      CI_lower    CI_upper          se\ngamma        0.28229408   0.161002878  0.40358528 0.061883266\nalpha       -8.82820947 -10.352701468 -7.30371747 0.777802040\nbeta_female -0.50670974  -0.834159350 -0.17926012 0.167066129\nbeta_age     0.01625468  -0.001753855  0.03426322 0.009188029\n```\n:::\n:::\n\n\nThe best way to understand your survival model is plotting its basic functions. So let's take a look at the survival function ($S(t)$) of our model.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# 10. Plot survival curve with 95% CI -----------------------------------------\n\n# 10.1 Use Delta Method to compute CIs across time of follow-up ===============\n\n# Get coefficents for Newuoa optimisation\nnewuoa_coef <- coef(opt)[\"newuoa\", ]\n\n# Compute CIs for a 60 year of female across time\nsurv_optim_female <- lapply(as.list(seq(0.01, 1000.01, 10)), function(t){\n\n  g <- paste(\"exp(-exp(alpha + beta_female + 60 * beta_age) *\", t,\n             \"^ exp(gamma))\")\n\n  fit <- deltaMethod(newuoa_coef, g, solve(hessian_m))\n\n  data.frame(time     = t,\n             estimate = fit[, \"Estimate\"],\n             ci_low   = fit[, \"2.5 %\"],\n             ci_up    = fit[, \"97.5 %\"])\n\n}) %>%\n  bind_rows()\n\n# 10.2 Plot survival curve with CIs ===========================================\nplot(surv_optim_female$time,\n     surv_optim_female$estimate,\n     ylim = c(0, 1),\n     type = \"n\",\n     xlab = \"Time in Days\",\n     ylab = \"S(t)\",\n     main = \"Survival after lung cancer for 60 year old females\")\npolygon(c(surv_optim_female$time, rev(surv_optim_female$time)),\n        c(surv_optim_female$ci_low, rev(surv_optim_female$ci_up)),\n        border = NA,\n        col = \"grey\")\nlines(surv_optim_female$time,\n      surv_optim_female$estimate)\nplot(weibull_model, type = \"survival\",\n     newdata = data.frame(age = 60,\n                          female = 1),\n     add = TRUE)\nlegend(0, 0.3,\n       fill = \"grey\",\n       \"95% CI\")\n```\n\n::: {.cell-output-display}\n![](optim_weibull_reg_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\nAdditionally, we can also plot our hazard function ($h(t)$).\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# 11. Plot hazard curve with 95% CI -------------------------------------------\n\n# 10.1 Use Delta Method to compute CIs across time of follow-up ===============\n\n# Get coefficents for Newuoa optimisation\nnewuoa_coef <- coef(opt)[\"newuoa\", ]\n\n# Compute CIs for a 60 year old female across time\nhaz_optim_female <- lapply(as.list(seq(0.01, 1000.01, 10)), function(t){\n\n  g <- paste(\"exp(gamma) * exp(alpha + beta_female + 60 * beta_age) *\", t,\n             \"^ (exp(gamma) - 1)\")\n\n  fit <- deltaMethod(newuoa_coef, g, solve(hessian_m))\n\n  data.frame(time     = t,\n             estimate = fit[, \"Estimate\"],\n             ci_low   = fit[, \"2.5 %\"],\n             ci_up    = fit[, \"97.5 %\"])\n\n}) %>%\n  bind_rows()\n\n# 10.2 Plot hazard curve with CIs =============================================\nplot(haz_optim_female$time,\n     haz_optim_female$estimate,\n     ylim = c(0, 0.005),\n     type = \"n\",\n     xlab = \"Time in Days\",\n     ylab = \"h(t)\",\n     main = \"Hazard of death after lung cancer for 60 year old females\")\npolygon(c(haz_optim_female$time, rev(haz_optim_female$time)),\n        c(haz_optim_female$ci_low, rev(haz_optim_female$ci_up)),\n        border = NA,\n        col = \"grey\")\nplot(weibull_model, type = \"hazard\",\n     newdata = data.frame(age = 60,\n                          female = 1),\n     add = TRUE)\nlines(haz_optim_female$time,\n      haz_optim_female$estimate)\nlegend(\"topleft\",\n       inset = 0.01,\n       cex = 0.8,\n       fill = c(\"black\", \"red\"),\n       legend = c(\"Optimix()\", \"flexsurvreg()\"),\n       box.lty = 0)\n```\n\n::: {.cell-output-display}\n![](optim_weibull_reg_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\nInterestingly, we see quite some differences between our estimates for the CI and <TT>flexsurvreg()</TT>'s estimates. Unfortunately, I didn't find a reason for this difference yet. So if you have a guess, please let me know.\n\nIn this post today we fitted a Weibull regression by optimising its likelihood function using the <TT>optimx()</TT> function from the <TT>{optimx}</TT> package. I hope you got some new insides and ideas by reading this post. If you have any comments or suggestions, I would be happy to hear from you via [email](mailto:joshuaentrop@posteo.de), [twitter](https://twitter.com/entjos) or [LinkedIn](https://www.linkedin.com/in/joshua-entrop/).\n",
    "supporting": [
      "optim_weibull_reg_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}